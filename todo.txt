db for provider links
------------------
write logs into db in different service
--------------------
add write logs in db into dir if provider doesnt respond to request 
-------------------------------
write fetching result in file and check if there same posts or not
----------
providers statistics in files. if 3 time provider is inactive then do not fetch him next time then next two times...
--------------------
check every link's status code - maybe they rename it or something
only status without body
------------
do http reqwest again for some unsuccess http statuses in vec of unsuccess links
reqwest::StatusCode::REQUEST_TIMEOUT 
let wrong_cases_thread = thread::spawn(move || {
refetch logic
-------------------
compute post's hash and send hashes from client app to server to check server already send them or not 
---
items: vec![BiorxivPageStructItem::new(); 30],
whats strange what only 30...weird
-----
rename some local variables in functions
------
service for date/time checking and executing arxiv for example one time per week and check of server restarted in this timestamp
-----------
problem - now code waiting for all http reqwests to complete. rewrite it into event loop
------
there is a problem with main arxiv link to check if provider available or not. and not only with arxiv
-----------
do some work on better differences in colors in prints
-------------
function to write save path from string and change some symbols
-------------
if size of working dir > 100mb then remove all containg
-----------------
write analog for twitter an use not only nitters
404 Not Found - CAUSE
This account's tweets are protected.
Only confirmed followers have access to @_KudoHiroyuki's tweets.
---------------------
https://doc.rust-lang.org/std/primitive.i32.html#method.checked_add
rewrite code in which there is a buffer overflow
--------------------
futures in some cases instead of threads (like file open or write in file)
-----------
thread pool instead of for loop
-----------
let _ = join_all(vec_of_write_into_files_futures).await; //todo: add state of success/unsuccess
-----------
if let Ok(something) = something.lock() {}
instead of 
something.lock().unwrap();
or match some none
----------
create big json file to test parsing speed
----------------------------
generate_biorxiv_hashmap_links and others rename this - remove hashmap
-------------------------------
thread pool with this let cpus = num_cpus::get();
--------------------
write some logic and flag what choose between config values, env and in code constants for more efficient production variant 
--------------------
pub const PROJECT_MODE: &str = "Development";//later as ENV variable only
----------------------------
todo: add medium
----------------------------
cannot do cargo build while docker build with this library = { path = "./library" }
----------------------------
parsing providers posts tests
----------------------------
server what running web tests every hour like http requests and get valid data or not
github parsing version to check different structs of posts as test in the loop
---------------------------
handle all todos in parse_github_html
-----------------------------
get concrete number of provider links as function or command line or env
-----------------------------
Add tests for new libraries versions and what version i use. 
Like http request to crates.io or something similar
-----------------------------
write test what checks if something missing in .dockerignore and .gitignore - local or ci? 
-----------------------------
todo: different todo for code and for tests
------------------------------
5 => {
                println!("todo 5 elements github parsing")
            }
github parsing
------------------------------
### pull and run postgres docker container
sudo docker run -p 5432:5432/tcp --name postgres-tufa-wsl2 -v ~/db-volumes/postgresql-volumes/tufa-dev-volume -e POSTGRES_PASSWORD=postgres -d postgres:latest

how to change default volume folder for this command?
and mongo
-----------------------------
colorful prints as lib
----------------------------
find this in code and fix "(todo change this print)" 
----------------------------
limit for mongo "get data" functions
----------------------------
move this from config 
mongodb://root:rootpassword@localhost:27017
mongodb+srv://mongodbcloudlogin:mongodbcloudpassword@tufa-mongo.y2xob.mongodb.net/myFirstDatabase?retryWrites=true&w=majority
to user credentials
----------------------------- 
#![deny(clippy::indexing_slicing, clippy::unwrap_used)]
clippy can warn/deny with this hashmap usage
use std::collections::HashMap;
fn main() {
  let mut hashmap = HashMap::new();
  hashmap.insert(
    "different key".to_string(),
    "value".to_string(),
  );
  //#1
  match hashmap.get("key") {
      Some(_) => {
          println!("key with get");
      }
      None => {
          println!("no key with get");
      }
  }
  //#2
  if hashmap.contains_key("key") {
    println!("key with contains_key");
  }
  else{
    println!("no key with contains_key");
  }
  //#3
  if hashmap["key"] == "value".to_string(){
    //thread 'main' panicked at 'no entry found for key',
    println!("key with scope");
  }
  else{
    println!("no key with scope");
  }
}
-----------------------------------
github parsing return in second parameter option<String, line! file!> to analize missing parse logic 
-----------------------------------
implement get_providers_link_parts with all success completed and with not all
test commit2
----------------------------------------------------------------
get_providers_link_parts whole and for each provider
and maybe rewrite it as struct with methods
----------------------------------------------------------------
test to check what cargo run executes in the right folder
----------------------------------------------------------------
remove enable prints for provider function parameter and move it to print_colorful_message
----------------------------------------------------------------
time measurement as prints_lib - check with config in implementation, not in function what use it 
----------------------------------------------------------------
somehow merge ProviderKind enum and in config vec_of_provider_names = ["arxiv", "biorxiv", "github", "habr", "medrxiv", "reddit", "twitter"]
--------------------------------------------------------------------------------------------------------------------------------
Resource::PostgreSql => { 
------------------------------------------------------------------------------------------------------
let mut vec_of_enums: Vec<ProviderKind> =
            Vec::with_capacity(CONFIG.params.vec_of_provider_names.len());
        //check if provider_names are unique
----------------------------------------------------------------
rename this check_new_posts_threads_parts
----------------------------------------------------------------
Struct itertools::structs::Unique
//check if provider_names are unique
            for provider_name in &CONFIG.params.vec_of_provider_names {
--------------------------------------------------------------------------------------------------------------------------------
rss_part Vec of link as input parameter (huge changes)